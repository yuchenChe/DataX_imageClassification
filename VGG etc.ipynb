{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c4a6d1f15a53445b8058bd5c941414c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_554084d4357f4032a3a1e07cbd5a793c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86b88fb294364bca9e0af5c354d7725a",
              "IPY_MODEL_43af4161548d41468adcabe4a7546d3f"
            ]
          }
        },
        "554084d4357f4032a3a1e07cbd5a793c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86b88fb294364bca9e0af5c354d7725a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2ac904186134852adce85b49891b301",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 87306240,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87306240,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5080572041b243e9b4f7f56536370f2b"
          }
        },
        "43af4161548d41468adcabe4a7546d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d03a76fed9094ce9a2e5299b98755855",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 83.3M/83.3M [00:11&lt;00:00, 7.75MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb0b231a430b47f1b3e35f180b4396a3"
          }
        },
        "b2ac904186134852adce85b49891b301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5080572041b243e9b4f7f56536370f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d03a76fed9094ce9a2e5299b98755855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb0b231a430b47f1b3e35f180b4396a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6mcZqV6nb4_",
        "colab_type": "code",
        "outputId": "ccc7d5aa-b73e-425b-fdaf-4b91caf55a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "6JnkfJImnY8N",
        "colab_type": "code",
        "outputId": "28691134-96c3-4ce4-9e06-410dc3a371cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "img_dir = \"/content/drive/My Drive/data-X/dataset/training_gallary\"\n",
        "data_path = os.path.join(img_dir,'*g')\n",
        "files = glob.glob(data_path)\n",
        "images = []\n",
        "for f1 in files:\n",
        "    img = cv2.imread(f1)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #convert from RGB to BGR\n",
        "    # img = img.transpose(2, 0, 1)\n",
        "    images.append(img)\n",
        "print(len(images))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XoGcr62nY8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "path = '/content/drive/My Drive/data-X/dataset/training_gallary'\n",
        "# Store the image file names in a list as long as they are jpgs\n",
        "image_names = [f for f in os.listdir(path) if os.path.splitext(f)[-1] == '.jpg']\n",
        "image_names = [int(i.split('.')[0]) for i in image_names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkwfNwUqnY8S",
        "colab_type": "code",
        "outputId": "f63919de-ffbc-467f-df34-64e2cd8922b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/My Drive/data-X/dataset/train.csv')\n",
        "train_p2b = pd.read_csv('/content/drive/My Drive/data-X/dataset/train_photo_to_biz_ids.csv')\n",
        "df = pd.merge(train_p2b, train, how='left',left_on='business_id',right_on='business_id')\n",
        "df['labels'] = df['labels'].astype(str)\n",
        "df['labels'] = df['labels'].apply(lambda x: [int(y) for y in x.split(' ') if y.isdigit()])\n",
        "names = pd.DataFrame(image_names)\n",
        "names = names.rename(columns={0: \"image_names\"})\n",
        "data = pd.merge(names, df, how='left', left_on='image_names',right_on='photo_id')\n",
        "labels = data['labels']\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_names</th>\n",
              "      <th>photo_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101085</td>\n",
              "      <td>101085</td>\n",
              "      <td>2759</td>\n",
              "      <td>[0, 3, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10118</td>\n",
              "      <td>10118</td>\n",
              "      <td>1801</td>\n",
              "      <td>[1, 2, 5, 6, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10116</td>\n",
              "      <td>10116</td>\n",
              "      <td>3816</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>101089</td>\n",
              "      <td>101089</td>\n",
              "      <td>2437</td>\n",
              "      <td>[3, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10119</td>\n",
              "      <td>10119</td>\n",
              "      <td>2480</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1293</th>\n",
              "      <td>100910</td>\n",
              "      <td>100910</td>\n",
              "      <td>2505</td>\n",
              "      <td>[0, 1, 6, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>100912</td>\n",
              "      <td>100912</td>\n",
              "      <td>1717</td>\n",
              "      <td>[1, 2, 4, 5, 6, 7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1295</th>\n",
              "      <td>101078</td>\n",
              "      <td>101078</td>\n",
              "      <td>501</td>\n",
              "      <td>[0, 4, 5, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1296</th>\n",
              "      <td>101081</td>\n",
              "      <td>101081</td>\n",
              "      <td>2820</td>\n",
              "      <td>[0, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1297</th>\n",
              "      <td>101083</td>\n",
              "      <td>101083</td>\n",
              "      <td>109</td>\n",
              "      <td>[1, 2, 3, 5, 6, 8]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1298 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      image_names  photo_id  business_id                    labels\n",
              "0          101085    101085         2759                 [0, 3, 8]\n",
              "1           10118     10118         1801           [1, 2, 5, 6, 8]\n",
              "2           10116     10116         3816  [1, 2, 3, 4, 5, 6, 7, 8]\n",
              "3          101089    101089         2437                    [3, 8]\n",
              "4           10119     10119         2480     [1, 2, 3, 4, 5, 6, 7]\n",
              "...           ...       ...          ...                       ...\n",
              "1293       100910    100910         2505              [0, 1, 6, 8]\n",
              "1294       100912    100912         1717        [1, 2, 4, 5, 6, 7]\n",
              "1295       101078    101078          501              [0, 4, 5, 8]\n",
              "1296       101081    101081         2820                    [0, 8]\n",
              "1297       101083    101083          109        [1, 2, 3, 5, 6, 8]\n",
              "\n",
              "[1298 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPKGy6EFnY8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_number = 200\n",
        "image_set = {\"train\": images[:-200], \"val\": images[-200:]}\n",
        "label_set = {\"train\": labels[:-200], \"val\": labels[-200:]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKFzPUf9nY8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function \n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2KqJzBznY8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"resnet\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "\n",
        "# Number of epochs to train for \n",
        "num_epochs = 15\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model, \n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUbUMT9NnY8c",
        "colab_type": "code",
        "outputId": "5d5ccf5a-b234-459d-fe43-8e5fcb5b339a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c4a6d1f15a53445b8058bd5c941414c7",
            "554084d4357f4032a3a1e07cbd5a793c",
            "86b88fb294364bca9e0af5c354d7725a",
            "43af4161548d41468adcabe4a7546d3f",
            "b2ac904186134852adce85b49891b301",
            "5080572041b243e9b4f7f56536370f2b",
            "d03a76fed9094ce9a2e5299b98755855",
            "eb0b231a430b47f1b3e35f180b4396a3"
          ]
        }
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet34\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet34(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3 \n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "    \n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4a6d1f15a53445b8058bd5c941414c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=87306240), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (5): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiF4OcuOnY8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def make_transform1(input_size):\n",
        "    return transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "def make_transform2(input_size):\n",
        "  return transforms.Compose([\n",
        "      transforms.ToPILImage(),\n",
        "      transforms.Resize((input_size, input_size)),\n",
        "      torchvision.transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5,), (0.5,))\n",
        "  ])\n",
        "\n",
        "\n",
        "\n",
        "class YelpDataset(Dataset):\n",
        "    def __init__(self, images, labels, label, transform):\n",
        "        self.transform = transform\n",
        "        Xp = []\n",
        "        Xn = []\n",
        "        for i, (X, y) in enumerate(zip(images, labels)):\n",
        "            if label in y:\n",
        "                Xp.append(transform(X))\n",
        "            else:\n",
        "                Xn.append(transform(X))\n",
        "        length = min(len(Xn), len(Xp))\n",
        "        self.X = Xp[:length] + Xn[:length]\n",
        "        self.y = [1 for _ in range(length)] + [0 for _ in range(length)]\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.X[idx], self.y[idx])\n",
        "\n",
        "dataloader = []\n",
        "for i in range(9):\n",
        "    dataset = {x : YelpDataset(image_set[x], label_set[x], i, make_transform2(input_size)) for x in ['train', 'val']}\n",
        "    dataloader.append({x: torch.utils.data.DataLoader(dataset[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYjk8Lb_nY8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhRH9SCQnY8i",
        "colab_type": "code",
        "outputId": "bccec90c-5274-4334-fd9f-61ccf54a8ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Send the model to GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are \n",
        "#  doing feature extract method# Send the model to GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are \n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIQ92RMFnY8p",
        "colab_type": "code",
        "outputId": "b1de3cb4-fdf2-449f-dff5-c63a335f5419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "m = []\n",
        "for i in range(9):\n",
        "  model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "  m.append(train_model(model_ft, dataloader[i], criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\")))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 1.0880 Acc: 0.5000\n",
            "val Loss: 1.0590 Acc: 0.5000\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 1.1088 Acc: 0.5000\n",
            "val Loss: 1.0946 Acc: 0.5000\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 1.0929 Acc: 0.5000\n",
            "val Loss: 1.0746 Acc: 0.4906\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 1.1115 Acc: 0.5000\n",
            "val Loss: 1.0760 Acc: 0.5000\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 1.0942 Acc: 0.5000\n",
            "val Loss: 1.0958 Acc: 0.5000\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 1.0912 Acc: 0.5000\n",
            "val Loss: 1.0878 Acc: 0.5000\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 1.1013 Acc: 0.4980\n",
            "val Loss: 1.1022 Acc: 0.5000\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 1.0947 Acc: 0.5000\n",
            "val Loss: 1.0756 Acc: 0.5000\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 1.1005 Acc: 0.5020\n",
            "val Loss: 1.1004 Acc: 0.5000\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 1.0957 Acc: 0.5000\n",
            "val Loss: 1.0520 Acc: 0.5000\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 1.0949 Acc: 0.4980\n",
            "val Loss: 1.1010 Acc: 0.5000\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 1.1047 Acc: 0.5020\n",
            "val Loss: 1.0834 Acc: 0.5000\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 1.0997 Acc: 0.5000\n",
            "val Loss: 1.1125 Acc: 0.5000\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 1.0905 Acc: 0.5000\n",
            "val Loss: 1.0980 Acc: 0.5000\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 1.1070 Acc: 0.5000\n",
            "val Loss: 1.1038 Acc: 0.5000\n",
            "\n",
            "Training complete in 12m 43s\n",
            "Best val Acc: 0.500000\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.9160 Acc: 0.5033\n",
            "val Loss: 0.9054 Acc: 0.5000\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.9106 Acc: 0.5054\n",
            "val Loss: 0.8980 Acc: 0.5000\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.9247 Acc: 0.4978\n",
            "val Loss: 0.8779 Acc: 0.5058\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.9242 Acc: 0.5000\n",
            "val Loss: 0.8904 Acc: 0.5058\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.9082 Acc: 0.5011\n",
            "val Loss: 0.8715 Acc: 0.4942\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.9125 Acc: 0.4957\n",
            "val Loss: 0.8915 Acc: 0.4942\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.9092 Acc: 0.4989\n",
            "val Loss: 0.8894 Acc: 0.5000\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.9181 Acc: 0.5000\n",
            "val Loss: 0.8897 Acc: 0.5000\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.9238 Acc: 0.4913\n",
            "val Loss: 0.9030 Acc: 0.5000\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.9154 Acc: 0.5000\n",
            "val Loss: 0.8819 Acc: 0.5058\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.9127 Acc: 0.5076\n",
            "val Loss: 0.8930 Acc: 0.5058\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.9165 Acc: 0.5043\n",
            "val Loss: 0.9117 Acc: 0.5000\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.9096 Acc: 0.5022\n",
            "val Loss: 0.9016 Acc: 0.5000\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.9072 Acc: 0.5054\n",
            "val Loss: 0.9003 Acc: 0.5000\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.9169 Acc: 0.4989\n",
            "val Loss: 0.8779 Acc: 0.4884\n",
            "\n",
            "Training complete in 23m 7s\n",
            "Best val Acc: 0.505814\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.8178 Acc: 0.4756\n",
            "val Loss: 0.8331 Acc: 0.4931\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.8112 Acc: 0.4961\n",
            "val Loss: 0.8209 Acc: 0.4861\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.8077 Acc: 0.5000\n",
            "val Loss: 0.8219 Acc: 0.4792\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.8157 Acc: 0.4923\n",
            "val Loss: 0.8523 Acc: 0.4722\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.8081 Acc: 0.4987\n",
            "val Loss: 0.8209 Acc: 0.4861\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.8065 Acc: 0.4910\n",
            "val Loss: 0.8209 Acc: 0.4722\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.8058 Acc: 0.4846\n",
            "val Loss: 0.8304 Acc: 0.4861\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.8070 Acc: 0.4987\n",
            "val Loss: 0.8252 Acc: 0.4792\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.7984 Acc: 0.4987\n",
            "val Loss: 0.8519 Acc: 0.4931\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.8083 Acc: 0.4897\n",
            "val Loss: 0.8540 Acc: 0.4931\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.8014 Acc: 0.5077\n",
            "val Loss: 0.8510 Acc: 0.5000\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.8106 Acc: 0.5013\n",
            "val Loss: 0.8364 Acc: 0.4931\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.7989 Acc: 0.4987\n",
            "val Loss: 0.8346 Acc: 0.5000\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.8138 Acc: 0.4923\n",
            "val Loss: 0.8389 Acc: 0.4722\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.8122 Acc: 0.4871\n",
            "val Loss: 0.8403 Acc: 0.5000\n",
            "\n",
            "Training complete in 19m 27s\n",
            "Best val Acc: 0.500000\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.7420 Acc: 0.4898\n",
            "val Loss: 0.7775 Acc: 0.4483\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.7411 Acc: 0.4806\n",
            "val Loss: 0.7872 Acc: 0.4138\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.7367 Acc: 0.4963\n",
            "val Loss: 0.7872 Acc: 0.4023\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.7405 Acc: 0.5111\n",
            "val Loss: 0.7850 Acc: 0.4310\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.7430 Acc: 0.4880\n",
            "val Loss: 0.7830 Acc: 0.4368\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.7414 Acc: 0.4769\n",
            "val Loss: 0.7797 Acc: 0.4195\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.7303 Acc: 0.5111\n",
            "val Loss: 0.7797 Acc: 0.4310\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.7371 Acc: 0.5083\n",
            "val Loss: 0.7822 Acc: 0.4425\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.7400 Acc: 0.4972\n",
            "val Loss: 0.7812 Acc: 0.4138\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.7480 Acc: 0.4760\n",
            "val Loss: 0.7835 Acc: 0.3966\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.7473 Acc: 0.4806\n",
            "val Loss: 0.7862 Acc: 0.4138\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.7404 Acc: 0.4834\n",
            "val Loss: 0.7934 Acc: 0.4138\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.7327 Acc: 0.4963\n",
            "val Loss: 0.7814 Acc: 0.4138\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.7470 Acc: 0.4686\n",
            "val Loss: 0.7814 Acc: 0.4368\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.7380 Acc: 0.4889\n",
            "val Loss: 0.7856 Acc: 0.3908\n",
            "\n",
            "Training complete in 26m 1s\n",
            "Best val Acc: 0.448276\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.7914 Acc: 0.4712\n",
            "val Loss: 0.8149 Acc: 0.4593\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.7930 Acc: 0.4867\n",
            "val Loss: 0.8216 Acc: 0.4651\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.7859 Acc: 0.4878\n",
            "val Loss: 0.8264 Acc: 0.4593\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.7975 Acc: 0.4613\n",
            "val Loss: 0.8293 Acc: 0.4535\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.8033 Acc: 0.4635\n",
            "val Loss: 0.8460 Acc: 0.4651\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.8089 Acc: 0.4668\n",
            "val Loss: 0.8367 Acc: 0.4593\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.8028 Acc: 0.4646\n",
            "val Loss: 0.8534 Acc: 0.4593\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.7909 Acc: 0.4823\n",
            "val Loss: 0.8274 Acc: 0.4593\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.7818 Acc: 0.4823\n",
            "val Loss: 0.8274 Acc: 0.4535\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.7910 Acc: 0.4912\n",
            "val Loss: 0.8331 Acc: 0.4535\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.7961 Acc: 0.4801\n",
            "val Loss: 0.8228 Acc: 0.4419\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.8019 Acc: 0.4735\n",
            "val Loss: 0.8305 Acc: 0.4535\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.7987 Acc: 0.4723\n",
            "val Loss: 0.8520 Acc: 0.4593\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.8091 Acc: 0.4613\n",
            "val Loss: 0.8211 Acc: 0.4651\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.7916 Acc: 0.4823\n",
            "val Loss: 0.8391 Acc: 0.4593\n",
            "\n",
            "Training complete in 22m 24s\n",
            "Best val Acc: 0.465116\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.7388 Acc: 0.4812\n",
            "val Loss: 0.7801 Acc: 0.4412\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.7306 Acc: 0.4846\n",
            "val Loss: 0.7861 Acc: 0.4314\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.7420 Acc: 0.4812\n",
            "val Loss: 0.7834 Acc: 0.4706\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.7429 Acc: 0.4932\n",
            "val Loss: 0.7957 Acc: 0.4412\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.7369 Acc: 0.4692\n",
            "val Loss: 0.7881 Acc: 0.4314\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.7370 Acc: 0.4949\n",
            "val Loss: 0.7887 Acc: 0.4314\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.7338 Acc: 0.4606\n",
            "val Loss: 0.7825 Acc: 0.4608\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.7511 Acc: 0.4606\n",
            "val Loss: 0.7884 Acc: 0.4510\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.7352 Acc: 0.4983\n",
            "val Loss: 0.7910 Acc: 0.4608\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.7338 Acc: 0.4829\n",
            "val Loss: 0.7846 Acc: 0.4510\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.7357 Acc: 0.4949\n",
            "val Loss: 0.7925 Acc: 0.4020\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.7336 Acc: 0.4897\n",
            "val Loss: 0.7914 Acc: 0.4510\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.7316 Acc: 0.4795\n",
            "val Loss: 0.7968 Acc: 0.4314\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.7434 Acc: 0.4503\n",
            "val Loss: 0.7915 Acc: 0.4314\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.7419 Acc: 0.4880\n",
            "val Loss: 0.7991 Acc: 0.3824\n",
            "\n",
            "Training complete in 14m 19s\n",
            "Best val Acc: 0.470588\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.7614 Acc: 0.5060\n",
            "val Loss: 0.7327 Acc: 0.5227\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.7605 Acc: 0.5319\n",
            "val Loss: 0.7235 Acc: 0.5341\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.7565 Acc: 0.5139\n",
            "val Loss: 0.7312 Acc: 0.5227\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.7546 Acc: 0.5259\n",
            "val Loss: 0.7325 Acc: 0.5114\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.7468 Acc: 0.5139\n",
            "val Loss: 0.7176 Acc: 0.5114\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.7564 Acc: 0.5339\n",
            "val Loss: 0.7388 Acc: 0.5227\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.7474 Acc: 0.5319\n",
            "val Loss: 0.7327 Acc: 0.5227\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.7548 Acc: 0.5179\n",
            "val Loss: 0.7237 Acc: 0.5227\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.7450 Acc: 0.5219\n",
            "val Loss: 0.7300 Acc: 0.5227\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.7491 Acc: 0.5259\n",
            "val Loss: 0.7123 Acc: 0.5114\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.7526 Acc: 0.5040\n",
            "val Loss: 0.7161 Acc: 0.5114\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.7436 Acc: 0.5319\n",
            "val Loss: 0.7320 Acc: 0.5227\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.7535 Acc: 0.5100\n",
            "val Loss: 0.7212 Acc: 0.5341\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.7529 Acc: 0.5299\n",
            "val Loss: 0.7167 Acc: 0.5227\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.7540 Acc: 0.5120\n",
            "val Loss: 0.7258 Acc: 0.5341\n",
            "\n",
            "Training complete in 12m 20s\n",
            "Best val Acc: 0.534091\n",
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.7213 Acc: 0.5175\n",
            "val Loss: 0.7485 Acc: 0.4872\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.7242 Acc: 0.4925\n",
            "val Loss: 0.7525 Acc: 0.4872\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.7210 Acc: 0.5301\n",
            "val Loss: 0.7459 Acc: 0.4679\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.7197 Acc: 0.5276\n",
            "val Loss: 0.7450 Acc: 0.4936\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.7278 Acc: 0.5138\n",
            "val Loss: 0.7471 Acc: 0.4808\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.7240 Acc: 0.5113\n",
            "val Loss: 0.7537 Acc: 0.4551\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.7138 Acc: 0.5226\n",
            "val Loss: 0.7442 Acc: 0.4872\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.7121 Acc: 0.5100\n",
            "val Loss: 0.7462 Acc: 0.4744\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.7202 Acc: 0.5113\n",
            "val Loss: 0.7474 Acc: 0.4679\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.7141 Acc: 0.5201\n",
            "val Loss: 0.7492 Acc: 0.5000\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.7206 Acc: 0.5138\n",
            "val Loss: 0.7462 Acc: 0.4872\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.7207 Acc: 0.5213\n",
            "val Loss: 0.7477 Acc: 0.5000\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.7199 Acc: 0.5150\n",
            "val Loss: 0.7454 Acc: 0.5000\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.7275 Acc: 0.4975\n",
            "val Loss: 0.7487 Acc: 0.5064\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.7232 Acc: 0.5000\n",
            "val Loss: 0.7528 Acc: 0.4808\n",
            "\n",
            "Training complete in 19m 43s\n",
            "Best val Acc: 0.506410\n",
            "Epoch 0/14\n",
            "----------\n",
            "val Loss: 0.8462 Acc: 0.5101\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.8147 Acc: 0.4953\n",
            "val Loss: 0.8331 Acc: 0.5152\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.8142 Acc: 0.5186\n",
            "val Loss: 0.8176 Acc: 0.5101\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.8230 Acc: 0.4944\n",
            "val Loss: 0.8373 Acc: 0.5303\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.8051 Acc: 0.5065\n",
            "val Loss: 0.8354 Acc: 0.5253\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.8233 Acc: 0.4898\n",
            "val Loss: 0.8165 Acc: 0.5253\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.8127 Acc: 0.5037\n",
            "val Loss: 0.8418 Acc: 0.5152\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.8191 Acc: 0.4898\n",
            "val Loss: 0.8120 Acc: 0.5303\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.8226 Acc: 0.4981\n",
            "val Loss: 0.8320 Acc: 0.5152\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.8141 Acc: 0.4981\n",
            "val Loss: 0.8253 Acc: 0.5202\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.8205 Acc: 0.4953\n",
            "val Loss: 0.8088 Acc: 0.5202\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.8135 Acc: 0.4944\n",
            "val Loss: 0.8219 Acc: 0.5152\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.8159 Acc: 0.4944\n",
            "val Loss: 0.8237 Acc: 0.5202\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.8213 Acc: 0.4953\n",
            "val Loss: 0.8083 Acc: 0.5152\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.8164 Acc: 0.4953\n",
            "val Loss: 0.8428 Acc: 0.5051\n",
            "\n",
            "Training complete in 26m 12s\n",
            "Best val Acc: 0.530303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfD47rS39nBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6cfccbe9-5d78-41c5-c6ed-e79173402df0"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "class YelpEvaluation(Dataset):\n",
        "  def __init__(self, X, y, transform):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    one_hot = torch.zeros(9)\n",
        "    one_hot.scatter_(0, torch.tensor(self.y[idx]), 1)\n",
        "    return (self.transform(self.X[idx]), one_hot)\n",
        "\n",
        "eval_dataset = YelpEvaluation(image_set['val'], list(label_set['val']), make_transform2(input_size))\n",
        "eval_dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "def evaluate(models, eval_dataloader):\n",
        "  running_ed = 0\n",
        "  running_cos_sim = 0\n",
        "  running_fbeta = 0\n",
        "  count = 0\n",
        "  for inputs, labels in eval_dataloader:\n",
        "    count += 1\n",
        "    preds = []\n",
        "    for m, _ in models:\n",
        "      m.eval()\n",
        "      p = m(inputs)\n",
        "      _, p = torch.max(m(inputs), dim=1)\n",
        "      preds.append(p.reshape(1, -1))\n",
        "    preds = torch.cat(preds, 0).transpose(0, 1)\n",
        "    running_ed += nn.functional.pairwise_distance(labels, preds).mean()\n",
        "    running_cos_sim += nn.functional.cosine_similarity(labels, preds).mean()\n",
        "    running_fbeta += fbeta_score(labels.cpu().detach().numpy().flatten(), preds.cpu().detach().numpy().flatten(), average='macro', beta=0.5)\n",
        "  print(f'euclidean_distances: {running_ed / count}' )\n",
        "  print(f'cosine_similarity: {running_cos_sim / count}' )\n",
        "  print(f'fbeta: {running_fbeta / count}' )\n",
        "\n",
        "evaluate(m, eval_dataloader)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "euclidean_distances: 2.266975164413452\n",
            "cosine_similarity: 0.3761448562145233\n",
            "fbeta: 0.417111094279377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdkrGCQuAJKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}